{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "No face found\n",
      "Sample collection complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "face_classifier=cv2.CascadeClassifier('C:/python/Python38/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_extractor(img):\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is():\n",
    "        return None\n",
    "    \n",
    "    for(x,y,w,h) in faces:\n",
    "        cropped_face=img[y:y+h, x:x+w]\n",
    "    return cropped_face\n",
    "    \n",
    "    \n",
    "cap=cv2.VideoCapture(0)\n",
    "count=0\n",
    "\n",
    "while(True):\n",
    "    ret, frame=cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count+=1\n",
    "        face=cv2.resize(face_extractor(frame),(200,200))\n",
    "        face=cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        \n",
    "        file_name_path='E:/faces/user'+str(count)+'.jpg'\n",
    "        \n",
    "        cv2.imwrite(file_name_path, face)\n",
    "        \n",
    "        cv2.putText(face, str(count),(50,50), cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "        cv2.imshow('Face Cropper',face)\n",
    "    else:\n",
    "        print('No face found')\n",
    "        pass\n",
    "    if cv2.waitKey(1)==13 or count==100:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('Sample collection complete')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Training_Data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-b0b81033127a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mimg_path\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0monlyfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mimages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mTraining_Data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mLabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mLabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Training_Data' is not defined"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "data_path='E:/faces/'\n",
    "onlyfiles=[f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "Traning_Data, Labels= [], []\n",
    "\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    img_path= data_path + onlyfiles[i]\n",
    "    images=cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "Labels=np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "model=cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print('Model Training Complete')\n",
    "face_classifier=cv2.CascadeClassifier('C:/python/Python38/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is():\n",
    "        return img,[]\n",
    "    \n",
    "    \n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y),(x+w,y+h),(0,255,0),2)\n",
    "        roi=imh[y:y+h, x:x+w]\n",
    "        roi=cv2.resize(roi,(200,200))\n",
    "    return img,roi\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    image, face=face_detector(frame)\n",
    "    try:\n",
    "        face=cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        result=model.predict(face)\n",
    "        \n",
    "        if result[1]<500:\n",
    "            confidence=100*(1-(result[1]/300))\n",
    "            display_string= str(confidence)+'% Confidence it is user'\n",
    "        cv2.putText(image, display_string,(100,120), cv2.FONT_HARSHEY_COMPLEX,1,(250,120,250),2)\n",
    "        \n",
    "        \n",
    "        if confidence>75:\n",
    "            cv2.putText(image,\"\"(250,450), cv2.FONT_HARSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.imshow('Face Cropper',image)\n",
    "        else:\n",
    "            cv2.putText(image,\"locked\"(250,450), cv2.FONT_HARSHEY_COMPLEX,1,(0,0,255),2)\n",
    "            cv2.imshow('Face Cropper',image)\n",
    "    except:\n",
    "        cv2.putText(image,\"Face Not Found\"(250,450), cv2.FONT_HARSHEY_COMPLEX,1,(255,0,0),2)\n",
    "        cv2.imshow('Face Cropper',image)\n",
    "        pass\n",
    "    if cv2.waitKey(1)==13 or count==100:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('Sample collection complete')\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-contrib-python\n",
      "  Downloading https://files.pythonhosted.org/packages/82/00/355af184a0f49fd4b5142b75a37080af999e84550e1ff6ac874d5d4caf5e/opencv_contrib_python-4.3.0.36-cp37-cp37m-win_amd64.whl (40.0MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from opencv-contrib-python) (1.16.4)\n",
      "Installing collected packages: opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.3.0.36\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BIF_create', 'EigenFaceRecognizer_create', 'FisherFaceRecognizer_create', 'LBPHFaceRecognizer_create', 'MACE_create', 'MACE_load', 'StandardCollector_create', '__doc__', '__loader__', '__name__', '__package__', '__spec__', 'createFacemarkAAM', 'createFacemarkKazemi', 'createFacemarkLBF', 'drawFacemarks', 'getFacesHAAR', 'loadDatasetList', 'loadFacePoints', 'loadTrainingData']\n",
      "Model Training Complete!!!!!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "data_path = 'E:/faces/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path,f))]\n",
    "\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "print(dir (cv2.face))\n",
    "\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "\n",
    "print(\"Model Training Complete!!!!!\")\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('C:/python/Python38/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml')\n",
    "def face_detector(img, size = 0.5):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "\n",
    "    if faces is():\n",
    "        return img,[]\n",
    "\n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200,200))\n",
    "\n",
    "    return img,roi\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    image, face = face_detector(frame)\n",
    "\n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        result = model.predict(face)\n",
    "\n",
    "        if result[1] < 500:\n",
    "            confidence = int(100*(1-(result[1])/300))\n",
    "            display_string = str(confidence)+'% Confidence it is user'\n",
    "        cv2.putText(image,display_string,(100,120), cv2.FONT_HERSHEY_COMPLEX,1,(250,120,255),2)\n",
    "\n",
    "\n",
    "        if confidence > 80:\n",
    "            cv2.putText(image, \"Kankana\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.imshow('Face Cropper', image)\n",
    "\n",
    "        else:\n",
    "            cv2.putText(image, \"Unknown\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.imshow('Face Cropper', image)\n",
    "\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"Face Not Found\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "        cv2.imshow('Face Cropper', image)\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1)==13:\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
